<!DOCTYPE html><html><head>
      <title>neural_network_types_with_examples</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css">
      
      
      <script src="https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.min.js"></script>
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="neural-network-architectures--code-focused-field-guide-pytorch--diagrams">Neural Network Architectures — Code-Focused Field Guide (PyTorch + Diagrams) </h1>
<p>A practical, code-oriented overview of key architectures: what they are, when to use them, with minimal PyTorch examples.</p>
<hr>
<h2 id="0-quick-when-to-use-what">0) Quick “when to use what” </h2>
<table>
<thead>
<tr>
<th>Modality / Task</th>
<th>First pick</th>
<th>Why</th>
<th>Alternatives</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tabular (CTR/ranking)</td>
<td>Wide &amp; Deep / DLRM</td>
<td>sparse IDs + dense feats</td>
<td>Plain MLP</td>
</tr>
<tr>
<td>Images (classification)</td>
<td>ResNet / ViT (pretrained)</td>
<td>strong transfer</td>
<td>ConvNeXt, EfficientNet</td>
</tr>
<tr>
<td>Images (segmentation)</td>
<td>U-Net / DeepLab</td>
<td>multi-scale + skips</td>
<td>FPN, Mask R-CNN</td>
</tr>
<tr>
<td>Text understanding</td>
<td>Encoder Transformer (BERT)</td>
<td>contextual reps</td>
<td>BiLSTM+CRF (small)</td>
</tr>
<tr>
<td>Text/code generation</td>
<td>Decoder Transformer (GPT)</td>
<td>SOTA generation</td>
<td>RNN-LM (on-device)</td>
</tr>
<tr>
<td>Seq2Seq (translation)</td>
<td>Encoder–Decoder (T5/BART)</td>
<td>alignment via attention</td>
<td>CTC+attention hybrids</td>
</tr>
<tr>
<td>Time series</td>
<td>TCN / Transformer</td>
<td>long horizon receptive field</td>
<td>S4/SSM, classical</td>
</tr>
<tr>
<td>Speech (streaming ASR)</td>
<td>RNN-T / Conformer</td>
<td>streaming + accuracy</td>
<td>CTC + chunking</td>
</tr>
<tr>
<td>Graphs</td>
<td>GCN/GAT/GraphSAGE</td>
<td>exploits edges</td>
<td>Graph Transformers</td>
</tr>
<tr>
<td>Retrieval/verification</td>
<td>Siamese/contrastive</td>
<td>metric space</td>
<td>Triplet, ArcFace</td>
</tr>
<tr>
<td>Generative (images)</td>
<td>Diffusion (Latent)</td>
<td>fidelity + stability</td>
<td>GANs, autoreg.</td>
</tr>
</tbody>
</table>
<hr>
<h1 id="1-mlp-multi-layer-perceptron">1) MLP (Multi-Layer Perceptron) </h1>
<p><strong>Use:</strong> tabular, small dense features, heads on top of encoders.</p>
<div class="mermaid">flowchart LR
    X[Input x] --&gt; L1[Linear + ReLU]
    L1 --&gt; DO1[Dropout]
    DO1 --&gt; L2[Linear + ReLU]
    L2 --&gt; Y[Linear -&gt; logits/y]
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> torch<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn <span class="token keyword keyword-as">as</span> nn

<span class="token keyword keyword-class">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_hidden<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> d_out<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hidden<span class="token punctuation">,</span> d_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hidden<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span>
		<span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># Tip: standardize features, use weight decay, early stop for tabular.</span>
</code></pre><p><strong>When:</strong> lots of dense engineered features or embeddings; otherwise CNN/Transformer often wins.</p>
<hr>
<h1 id="2-cnns-resnet-style">2) CNNs (ResNet-style) </h1>
<p><strong>Use:</strong> images (and 2D/1D signals). Translation equivariance, local filters.</p>
<div class="mermaid">graph LR
    x(Input) --&gt;|3x3 conv| b1(Conv-BN-ReLU)
    b1 --&gt; b2(Conv-BN)
    b2 --&gt; add{{+ skip}}
    add --&gt; relu(ReLU) --&gt; out(Output)
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">BasicBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>c<span class="token punctuation">)</span>

	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
		identity <span class="token operator">=</span> x
		out <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		out <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span>
		out <span class="token operator">+=</span> identity
		<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

<span class="token keyword keyword-class">class</span> <span class="token class-name">TinyResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_ch<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>stem <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_ch<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>BasicBlock<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> _ <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>stem<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># global avg pool</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre><p><strong>Tips:</strong> transfer-learn from ResNet-50 (freeze most layers; train head), use augmentations (mixup, CutMix), cosine LR with warmup.</p>
<hr>
<h1 id="3-u-net-encoderdecoder-with-skips">3) U-Net (Encoder–Decoder with skips) </h1>
<p><strong>Use:</strong> segmentation, denoising, image-to-image.</p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>Encoder: conv ↓ ↓ ↓
            ↘    ↘
Skips  ───────────┐
Decoder:      ↑ ↑ ↑ with concat
</code></pre><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">ConvBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c_in<span class="token punctuation">,</span> c_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>block <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c_in<span class="token punctuation">,</span> c_out<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c_out<span class="token punctuation">,</span> c_out<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>block<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword keyword-class">class</span> <span class="token class-name">UNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_ch<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_ch<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> base<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>down1 <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>in_ch<span class="token punctuation">,</span> base<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>down2 <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>base<span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>down3 <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

		self<span class="token punctuation">.</span>bottleneck <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">8</span><span class="token punctuation">)</span>

		self<span class="token punctuation">.</span>up3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">8</span><span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>dec3 <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">8</span><span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>up2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>dec2 <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> base<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>up1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">,</span> base<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>dec1 <span class="token operator">=</span> ConvBlock<span class="token punctuation">(</span>base<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">,</span> base<span class="token punctuation">)</span>

		self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>base<span class="token punctuation">,</span> out_ch<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
		s1 <span class="token operator">=</span> self<span class="token punctuation">.</span>down1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>s1<span class="token punctuation">)</span>
		s2 <span class="token operator">=</span> self<span class="token punctuation">.</span>down2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>s2<span class="token punctuation">)</span>
		s3 <span class="token operator">=</span> self<span class="token punctuation">.</span>down3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>s3<span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>bottleneck<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>up3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> s3<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>dec3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>up2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> s2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>dec2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>up1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> s1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>dec1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre><p><strong>Tips:</strong> use Dice/Focal loss with class imbalance; deep supervision helps.</p>
<hr>
<h1 id="4-rnns-vanilla--lstm--gru">4) RNNs (Vanilla / LSTM / GRU) </h1>
<p><strong>Use:</strong> streaming/online sequence modeling, low latency.</p>
<p><strong>Diagram A</strong></p>
<div class="mermaid">flowchart LR
    h0["h(t-1)"] --&gt; cell["RNN Cell"]
    xt["x(t)"] --&gt; cell
    cell --&gt; ht["h(t)"]
    ht --&gt; yhat["y_hat(t)"]
</div><p><strong>Diagram B</strong></p>
<div class="mermaid">flowchart TD
    h0["h(t-1)"] --&gt; cell["RNN Cell"]
    xt["x(t)"] --&gt; cell
    cell --&gt; ht["h(t)"]
    ht --&gt; yhat["y_hat(t)"]
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">TinyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_hid<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_hid<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># or nn.LSTM</span>
		self<span class="token punctuation">.</span>head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hid<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> h0<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token comment"># x: (B, T, d_in)</span>
		h<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h0<span class="token punctuation">)</span>
		logits <span class="token operator">=</span> self<span class="token punctuation">.</span>head<span class="token punctuation">(</span>h<span class="token punctuation">)</span>       <span class="token comment"># (B, T, d_out)</span>
		<span class="token keyword keyword-return">return</span> logits
</code></pre><p><strong>Tips:</strong> orthogonal init for recurrent weights; gradient clipping; use LSTM/GRU over vanilla; RNN-T for streaming ASR.</p>
<hr>
<h1 id="5-temporal-convolutional-networks-tcn">5) Temporal Convolutional Networks (TCN) </h1>
<p><strong>Use:</strong> time series forecasting/classification with long receptive fields.</p>
<p><strong>Diagram A</strong></p>
<div class="mermaid">flowchart TD
    x["Input x"] --&gt; B1["Conv1d (dilation=1)\nReLU\n+ Residual"]
    B1 --&gt; B2["Conv1d (dilation=2)\nReLU\n+ Residual"]
    B2 --&gt; B3["Conv1d (dilation=4)\nReLU\n+ Residual"]
    B3 --&gt; y["Output y"]
</div><p><strong>Diagram B</strong></p>
<div class="mermaid">flowchart TD
    x["x"] --&gt; B1["Conv1d d=1 → ReLU → Residual"]
    B1 --&gt; B2["Conv1d d=2 → ReLU → Residual"]
    B2 --&gt; B3["Conv1d d=4 → ReLU → Residual"]
    B3 --&gt; y["y"]
</div><p><strong>Diagram C</strong></p>
<div class="mermaid">flowchart LR
    x["x"] --&gt; B1["Conv1d d=1 → ReLU → Residual"]
    B1 --&gt; B2["Conv1d d=2 → ReLU → Residual"]
    B2 --&gt; B3["Conv1d d=4 → ReLU → Residual"]
    B3 --&gt; y["y"]
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">TCNBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> k<span class="token punctuation">,</span> padding<span class="token operator">=</span>dilation<span class="token operator">*</span><span class="token punctuation">(</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span>dilation<span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> k<span class="token punctuation">,</span> padding<span class="token operator">=</span>dilation<span class="token operator">*</span><span class="token punctuation">(</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span>dilation<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> x<span class="token punctuation">)</span>

<span class="token keyword keyword-class">class</span> <span class="token class-name">TinyTCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_hid<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_hid<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			TCNBlock<span class="token punctuation">(</span>d_hid<span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			TCNBlock<span class="token punctuation">(</span>d_hid<span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			TCNBlock<span class="token punctuation">(</span>d_hid<span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>d_hid<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># x: (B, T, d_in)</span>
		x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		x <span class="token operator">=</span> self<span class="token punctuation">.</span>blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>head<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># (B,T,d_out)</span>
</code></pre><hr>
<h1 id="6-transformers-encoder--decoder--enc-dec">6) Transformers (Encoder / Decoder / Enc-Dec) </h1>
<p><strong>Use:</strong> text/code, long-range dependencies, scalable transfer.</p>
<div class="mermaid">flowchart TB
    subgraph EncoderBlock
        LN1 --&gt; MHSA[Multi-Head Self-Attn] --&gt; Add1
        Add1 --&gt; LN2 --&gt; MLP --&gt; Add2
    end
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">MHSA</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> n_heads<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		<span class="token keyword keyword-assert">assert</span> d_model <span class="token operator">%</span> n_heads <span class="token operator">==</span> <span class="token number">0</span>
		self<span class="token punctuation">.</span>nh <span class="token operator">=</span> n_heads<span class="token punctuation">;</span> self<span class="token punctuation">.</span>dk <span class="token operator">=</span> d_model <span class="token operator">//</span> n_heads
		self<span class="token punctuation">.</span>qkv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> <span class="token number">3</span><span class="token operator">*</span>d_model<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>

	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		B<span class="token punctuation">,</span>T<span class="token punctuation">,</span>D <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
		q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>v <span class="token operator">=</span> self<span class="token punctuation">.</span>qkv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (B,T,D) each</span>
		<span class="token keyword keyword-def">def</span> <span class="token function">split</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword keyword-return">return</span> t<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span>T<span class="token punctuation">,</span>self<span class="token punctuation">.</span>nh<span class="token punctuation">,</span>self<span class="token punctuation">.</span>dk<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># (B,nh,T,dk)</span>
		q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>v <span class="token operator">=</span> <span class="token builtin">map</span><span class="token punctuation">(</span>split<span class="token punctuation">,</span> <span class="token punctuation">(</span>q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span>
		scores <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>dk<span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># (B,nh,T,T)</span>
		<span class="token keyword keyword-if">if</span> mask <span class="token keyword keyword-is">is</span> <span class="token keyword keyword-not">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span> scores <span class="token operator">=</span> scores<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>mask<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1e9</span><span class="token punctuation">)</span>
		w <span class="token operator">=</span> scores<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
		attn <span class="token operator">=</span> w @ v                                  <span class="token comment"># (B,nh,T,dk)</span>
		attn <span class="token operator">=</span> attn<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span>T<span class="token punctuation">,</span>D<span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>

<span class="token keyword keyword-class">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> n_heads<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> d_ff<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>ln1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>attn <span class="token operator">=</span> MHSA<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> n_heads<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>ln2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>ff <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_ff<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_ff<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ln1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> mask<span class="token punctuation">)</span>
		x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>ff<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ln2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> x
</code></pre><p><strong>Tips:</strong> use pretrained checkpoints; for long sequences consider efficient attention (Performer/Longformer) or SSMs; tune LR with warmup + cosine; apply weight decay to weights (exclude LayerNorm/bias).</p>
<hr>
<h1 id="7-graph-neural-networks-gcngat">7) Graph Neural Networks (GCN/GAT) </h1>
<p><strong>Use:</strong> data with nodes + edges (molecules, social nets, KGs).</p>
<p><strong>Diagram A</strong></p>
<div class="mermaid">flowchart LR
    A(("v_i")) -- "aggregate neighbors" --&gt; H1["h_i^(1)"]
    H1 --&gt; H2["h_i^(2)"]
</div><p><strong>Diagram B</strong></p>
<div class="mermaid">flowchart LR
    A["node v_i"] -- "aggregate neighbors" --&gt; H1["h(i,1)"]
    H1 --&gt; H2["h(i,2)"]
</div><p><strong>Diagram C</strong></p>
<div class="mermaid">flowchart LR
    A["vi"] -- "aggregate neighbors" --&gt; H1["hi_1"]
    H1 --&gt; H2["hi_2"]
</div><blockquote>
<p><strong>GCN layer (message passing):</strong> (H^{(l+1)} = \sigma(\hat{D}<sup>{-1/2}\hat{A}\hat{D}</sup>{-1/2} H^{(l)} W^{(l)}))</p>
</blockquote>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">GCNLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>lin <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_out<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> A_hat<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># X: (N,d), A_hat: normalized adj (N,N)</span>
		<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>A_hat @ self<span class="token punctuation">.</span>lin<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Minimal forward:</span>
<span class="token comment"># A_hat = add_self_loops_and_normalize(A)  # precompute once</span>
<span class="token comment"># X -&gt; GCNLayer -&gt; GCNLayer -&gt; readout (mean/sum pooling) -&gt; MLP</span>
</code></pre><p><strong>Tips:</strong> sample neighborhoods on large graphs; add residuals &amp; norms; handle class imbalance with weighted loss.</p>
<hr>
<h1 id="8-siamese--contrastive-metric-learning">8) Siamese / Contrastive (Metric Learning) </h1>
<p><strong>Use:</strong> retrieval, verification, deduplication (face/voice), CLIP-style.</p>
<div class="mermaid">flowchart LR
    xa[x_a] --&gt; Enc[Encoder f_\theta] --&gt; za[z_a]
    xb[x_b] --&gt; Enc --&gt; zb[z_b]
    za --- contrastive_loss --- zb
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_in<span class="token punctuation">,</span> d_emb<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> d_emb<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword keyword-return">return</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword keyword-def">def</span> <span class="token function">contrastive_loss</span><span class="token punctuation">(</span>z_a<span class="token punctuation">,</span> z_b<span class="token punctuation">,</span> tau<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	sim <span class="token operator">=</span> z_a @ z_b<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> tau                       <span class="token comment"># (B,B)</span>
	target <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>z_a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>z_a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
	<span class="token keyword keyword-return">return</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>sim<span class="token punctuation">,</span> target<span class="token punctuation">)</span>       <span class="token comment"># InfoNCE (a-&gt;b); often add b-&gt;a</span>
</code></pre><p><strong>Tips:</strong> batch composition matters (hard negatives); use temperature; consider margin losses (ArcFace) for classification-as-metric.</p>
<hr>
<h1 id="9-recommenders-wide--deep">9) Recommenders (Wide &amp; Deep) </h1>
<p><strong>Use:</strong> sparse categorical IDs + dense numerical features.</p>
<div class="mermaid">flowchart LR
    id1[Cat IDs] --&gt; Emb[Embeddings] --&gt; Deep[MLP]
    dense[Dense feats] --&gt;|concat| Deep
    cross[Cross terms] --&gt; Wide[Linear]
    Wide --&gt; Out
    Deep --&gt; Out[Sigmoid/Softmax]
</div><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">WideAndDeep</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_ids<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> d_dense<span class="token punctuation">,</span> d_hidden<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_ids<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>deep <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>emb_dim <span class="token operator">+</span> d_dense<span class="token punctuation">,</span> d_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hidden<span class="token punctuation">,</span> d_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>wide <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_dense<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># example: linear over dense (add crosses externally)</span>
		self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hidden<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> dense<span class="token punctuation">)</span><span class="token punctuation">:</span>
		e <span class="token operator">=</span> self<span class="token punctuation">.</span>emb<span class="token punctuation">(</span>ids<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>       <span class="token comment"># bag multiple IDs: (B, M, emb) -&gt; (B, emb)</span>
		deep_out <span class="token operator">=</span> self<span class="token punctuation">.</span>deep<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>e<span class="token punctuation">,</span> dense<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		logit <span class="token operator">=</span> self<span class="token punctuation">.</span>wide<span class="token punctuation">(</span>dense<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>deep_out<span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>logit<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><p><strong>Tips:</strong> embeddings dominate memory → consider quantization/sharding; calibrate outputs (Platt/temperature).</p>
<hr>
<h1 id="10-diffusion-ddpm--toy-skeleton">10) Diffusion (DDPM — toy skeleton) </h1>
<p><strong>Use:</strong> high-fidelity generation (images/audio). Below is a minimal 1D sketch.</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">TinyUNet1D</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t_emb<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># t_emb ignored here; real models condition on t</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># Training loop idea (toy):</span>
<span class="token comment"># sample t ~ Uniform({1..T}); add noise ε to x0 to get xt; predict ε</span>
<span class="token comment"># loss = ||ε - ε_theta(xt, t)||^2</span>
</code></pre><p><strong>Tips:</strong> use sinusoidal time embeddings, U-Net backbones, cosine noise schedules; classifier-free guidance for conditional tasks; latent diffusion for speed.</p>
<hr>
<h1 id="11-normalizing-flows-realnvp-style-affine-coupling">11) Normalizing Flows (RealNVP-style affine coupling) </h1>
<p><strong>Use:</strong> exact likelihood + sampling.</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-class">class</span> <span class="token class-name">AffineCoupling</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d<span class="token punctuation">,</span> d<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>t <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d<span class="token punctuation">,</span> d<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		x1<span class="token punctuation">,</span> x2 <span class="token operator">=</span> x<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
		s<span class="token punctuation">,</span> t <span class="token operator">=</span> self<span class="token punctuation">.</span>s<span class="token punctuation">(</span>x1<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
		<span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> reverse<span class="token punctuation">:</span>
			y2 <span class="token operator">=</span> x2 <span class="token operator">*</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">+</span> t
			logdet <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
		<span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
			y2 <span class="token operator">=</span> <span class="token punctuation">(</span>x2 <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>s<span class="token punctuation">)</span>
			logdet <span class="token operator">=</span> <span class="token operator">-</span>s<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x1<span class="token punctuation">,</span> y2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> logdet
</code></pre><p><strong>Tips:</strong> stack many couplings + permutations; track log-det sums; careful init to stabilize training.</p>
<hr>
<h1 id="12-state-space--long-sequence-s4-style-intuition">12) State-Space / Long-Sequence (S4-style intuition) </h1>
<p><strong>Use:</strong> very long sequences with sub-quadratic cost.</p>
<p><em>Idea:</em> learn a linear time-invariant system ( x_{t+1}=Ax_t+Bu_t,\ y_t=Cx_t+Du_t ) discretized and convolved efficiently.</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Toy stand-in: depthwise 1D conv with long kernels (a crude SSM proxy)</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">LongConv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>dw <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> k<span class="token punctuation">,</span> groups<span class="token operator">=</span>d_model<span class="token punctuation">,</span> padding<span class="token operator">=</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>ln <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>                   <span class="token comment"># x: (B,T,D)</span>
		y <span class="token operator">=</span> self<span class="token punctuation">.</span>dw<span class="token punctuation">(</span>x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>ln<span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span>
</code></pre><p><strong>Tips:</strong> if you need 10k+ context lengths with reasonable memory, try S4/Hyena; combine with attention for hybrid models.</p>
<hr>
<h1 id="13-training-patterns-that-generalize">13) Training patterns that generalize </h1>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e-4</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment"># AdamW, exclude norms/bias from decay</span>
	decay<span class="token punctuation">,</span> no_decay <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	<span class="token keyword keyword-for">for</span> n<span class="token punctuation">,</span> p <span class="token keyword keyword-in">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span> <span class="token keyword keyword-continue">continue</span>
		<span class="token keyword keyword-if">if</span> p<span class="token punctuation">.</span>ndim <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">:</span> decay<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span>      <span class="token comment"># weights</span>
		<span class="token keyword keyword-else">else</span><span class="token punctuation">:</span> no_decay<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span>             <span class="token comment"># bias, LayerNorm, etc.</span>
	<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span><span class="token punctuation">[</span>
		<span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> decay<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> wd<span class="token punctuation">}</span><span class="token punctuation">,</span>
		<span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> no_decay<span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>

<span class="token keyword keyword-def">def</span> <span class="token function">cosine_schedule</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> warmup_steps<span class="token punctuation">,</span> total_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword keyword-def">def</span> <span class="token function">lr_lambda</span><span class="token punctuation">(</span>step<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token keyword keyword-if">if</span> step <span class="token operator">&lt;</span> warmup_steps<span class="token punctuation">:</span>
			<span class="token keyword keyword-return">return</span> step <span class="token operator">/</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> warmup_steps<span class="token punctuation">)</span>
		progress <span class="token operator">=</span> <span class="token punctuation">(</span>step <span class="token operator">-</span> warmup_steps<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> total_steps <span class="token operator">-</span> warmup_steps<span class="token punctuation">)</span>
		<span class="token keyword keyword-return">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>pi <span class="token operator">*</span> progress<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-return">return</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token punctuation">)</span>
</code></pre><p><strong>Other tips</strong></p>
<ul>
<li>Initialize: Xavier for <code>tanh</code>, He/Kaiming for ReLU; orthogonal recurrent matrices.</li>
<li>Regularize: dropout, data augmentation, label smoothing, early stopping.</li>
<li>Stabilize: gradient clipping for RNN/Transformer; mixed precision (AMP); gradient accumulation.</li>
</ul>
<hr>
<h1 id="14-evaluation--selection-checklist">14) Evaluation &amp; selection checklist </h1>
<ol>
<li><strong>Data shape &amp; scale:</strong> images vs text vs graphs; label count; class imbalance.</li>
<li><strong>Context length / latency:</strong> streaming? on-device? pick RNN/TCN/efficient attention when needed.</li>
<li><strong>Inductive bias:</strong> do you have spatial/temporal/graph structure? choose CNN/TCN/GNN.</li>
<li><strong>Compute budget:</strong> pretrained encoders and adapters (LoRA) save time &amp; energy.</li>
<li><strong>Metrics:</strong> accuracy vs F1 vs AUROC vs calibration; latency/throughput in deployment.</li>
</ol>
<hr>
<h1 id="15-minimal-training-loop-template-classification">15) Minimal training loop template (classification) </h1>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">train_epoch</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> scheduler<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> clip<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> total<span class="token operator">=</span>correct<span class="token operator">=</span><span class="token number">0</span>
	criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-for">for</span> x<span class="token punctuation">,</span> y <span class="token keyword keyword-in">in</span> loader<span class="token punctuation">:</span>
		x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
		optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span>set_to_none<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
		logits <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
		loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
		loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
		nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> clip<span class="token punctuation">)</span>
		optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
		<span class="token keyword keyword-if">if</span> scheduler<span class="token punctuation">:</span> scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
		total <span class="token operator">+=</span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span> correct <span class="token operator">+=</span> <span class="token punctuation">(</span>logits<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">==</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
	<span class="token keyword keyword-return">return</span> correct<span class="token operator">/</span>total
</code></pre><hr>
<h1 id="16-common-gotchas">16) Common “gotchas” </h1>
<ul>
<li><strong>Overfit on tabular:</strong> trees often beat MLPs unless you have large data + embeddings.</li>
<li><strong>BatchNorm with tiny batches:</strong> switch to GroupNorm/LayerNorm for stability.</li>
<li><strong>Weight decay on norms/biases:</strong> usually exclude (see optimizer config above).</li>
<li><strong>Class imbalance:</strong> use weighted loss, focal loss, or resampling.</li>
<li><strong>Sequence padding:</strong> use masks in attention; avoid learning from padding tokens.</li>
</ul>
<hr>
<h1 id="17-where-to-go-deeper-topics-to-searchstudy-next">17) Where to go deeper (topics to search/study next) </h1>
<ul>
<li><strong>Vision:</strong> ResNet, ConvNeXt, ViT, Swin, UNet, DETR.</li>
<li><strong>NLP:</strong> BERT, T5, GPT; LoRA/adapters; instruction tuning; retrieval-augmented gen.</li>
<li><strong>Audio/Speech:</strong> Conformer, wav2vec 2.0, HuBERT, RNN-T.</li>
<li><strong>Graphs:</strong> GCN, GAT, GraphSAGE, Graph Transformer; positional encodings.</li>
<li><strong>Generative:</strong> VAE, GAN, Flows, Diffusion; classifier-free guidance; latent diffusion.</li>
<li><strong>Long-context:</strong> Performer, Longformer, S4/Hyena; memory modules.</li>
</ul>
<hr>
<h2 id="appendix-tiny-starter-datasets--shapes">Appendix: tiny “starter” datasets &amp; shapes </h2>
<ul>
<li><strong>Images:</strong> (B,3,H,W) → CNN/ViT; normalize to ImageNet stats for transfer.</li>
<li><strong>Text:</strong> token ids (B,T) → embedding + Transformer; pad + attention mask.</li>
<li><strong>Time series:</strong> (B,T,features) → TCN/RNN; z-score per feature.</li>
<li><strong>Graphs:</strong> node features (N,d), edges (E×2) → GNN; build normalized adjacency.</li>
<li><strong>Tabular:</strong> dense (B,d) + sparse IDs (B,M) → embeddings + MLP head.</li>
</ul>
<hr>

      </div>
      
      
    
    
    <script type="module">
// TODO: If ZenUML gets integrated into mermaid in the future,
//      we can remove the following lines.


var MERMAID_CONFIG = ({"startOnLoad":false});
if (typeof MERMAID_CONFIG !== 'undefined') {
  MERMAID_CONFIG.startOnLoad = false
  MERMAID_CONFIG.cloneCssStyles = false
  MERMAID_CONFIG.theme = "default"
}

mermaid.initialize(MERMAID_CONFIG || {})
if (typeof(window['Reveal']) !== 'undefined') {
  function mermaidRevealHelper(event) {
    var currentSlide = event.currentSlide
    var diagrams = currentSlide.querySelectorAll('.mermaid')
    for (var i = 0; i < diagrams.length; i++) {
      var diagram = diagrams[i]
      if (!diagram.hasAttribute('data-processed')) {
        mermaid.init(null, diagram, ()=> {
          Reveal.slide(event.indexh, event.indexv)
        })
      }
    }
  }
  Reveal.addEventListener('slidetransitionend', mermaidRevealHelper)
  Reveal.addEventListener('ready', mermaidRevealHelper)
  await mermaid.run({
    nodes: document.querySelectorAll('.mermaid')
  })
} else {
  await mermaid.run({
    nodes: document.querySelectorAll('.mermaid')
  })
}
</script>
    
    
    
  
    </body></html>